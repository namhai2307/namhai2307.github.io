<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, shrink-to-fit=no">
    <title>Project Page - Brand</title>
    <link rel="icon" href="assets\image material\logobrand_tempo.png" type="image/x-icon">
    <link rel="stylesheet" href="assets/bootstrap/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,400,700">
    <link rel="stylesheet" href="assets/fonts/ionicons.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pikaday/1.6.1/css/pikaday.min.css">
    <link rel="stylesheet" href="assets/css/untitled.css">
    <style>
        .layer1 {
  position: relative;
  z-index: 1;
        }

        .layer2 {
  position: absolute;
  top: 20px;
  left: 20px;
  z-index: 2;
        }

/* Add CSS to style the code container */
.code-container {
    background-color: #f4f4f4;
    border: 1px solid #ddd;
    border-radius: 5px;
    padding: 10px;
    margin-bottom: 20px;
    overflow-x: auto; /* Enable horizontal scroll if needed */
}

/* Optional: Add CSS to style the code within the container */
.code-container pre {
    margin: 0;
    padding: 0;
}

.code-container code {
    font-family: 'Courier New', Courier, monospace;
}

    </style>
</head>

<body>
    <nav class="navbar navbar-dark navbar-expand-lg fixed-top bg-white portfolio-navbar gradient">
        <div class="container"><a class="navbar-brand logo" href="#"><b>TRAN HAI NAM</b></a><button data-bs-toggle="collapse" class="navbar-toggler" data-bs-target="#navbarNav"><span class="visually-hidden">Toggle navigation</span><span class="navbar-toggler-icon"></span></button>
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav ms-auto">
                    <li class="nav-item"><a class="nav-link" href="index.html">Home</a></li>
                    <li class="nav-item"><a class="nav-link" href="projects-grid-cards.html">Projects</a></li>
                    <li class="nav-item"><a class="nav-link" href="cv.html">CV</a></li>
                    <li class="nav-item"><a class="nav-link" href="my_journey_new.html">My Journey</a></li>
                    <li class="nav-item"><a class="nav-link" href="hire-me.html">Hire me</a></li>
                </ul>
            </div>
        </div>
    </nav>
    <main class="page project-page">
        <section class="portfolio-block project">
            <div class="container">
                <div class="heading">
                    <h2>Python Automated Jobs Scraping Bot</h2>
                </div>
                <div class="image" style="background-image:url(&quot;assets/img/tech/python-logo.jpg&quot;);"></div>
                <div class="row">
                    <div class="col-12 col-md-6 offset-md-1 info">
                        <h3>Description</h3>
                        <p>Getting too tired from searching for jobs manually and going around Perth CBD to give people my resume during my first summmer break in Australia, I developed a jobs scraping bot to automate the process of looking for jobs and internships</p>
                        <p>This project help me applied the theoretical knowledge that I learned from the Python unit(CITS1401) at UWA during my first semester into practical tools.</p>
                        <p></p>
                        <h3>Overview</h3>
                        <p>The simple script use BeautifulSoup and requests module to gather information includes: job's title, position, company's name, location, salary, level and links to the jobs all store within a csv file and use regex module to filter out texts from raw html code. All resources are on my github: <a href="https://github.com/namhai2307/Automated-jobs-scraping-bot">https://github.com/namhai2307/Automated-jobs-scraping-bot</a>.</p>
                        <p><b>Scope:</b> Automatically gather jobs description and store them in an excel file so I can browse in one go instead of manually clicking on every single one.</p>
                        <p>Result preview: <a href="assets\project_2\data_set_1.csv">List of electrical engineering jobs</a></p>
                        <h5>Importing relevant libraries:</h5>
                        <div class="code-container">
                            <pre>
                                <code class="language-python">
#import relevant module
import csv
from datetime import datetime
from bs4 import BeautifulSoup
import requests
import re
lst_links = []
lst_name = []
lst_company = []
big_lst = []
lst_location = []
lst_position = []
lst_salary = []
lst_level = []
                                </code>
                            </pre>
                        </div>

                        <h5>Defines the main function and interacting with the web:</h5>
                        <div class="code-container">
                            <pre>
                                <code>
#interacting with the web
def extract(url):
    #extract raw html
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    cards = soup.find_all('div', 'y735df0 _1iz8dgs4y _1iz8dgs4w')
                                </code>
                            </pre>
                        </div>

                        <h5>Extracting data from each job card and storing them in respective lists:</h5>
                        <p>Noted that from this point every piece of code will be within the main function</p>
                        <div class="code-container">
                            <pre>
                                <code>
    for i in lst_links:
        jobs_rep = requests.get(i)
        jobs_soup = BeautifulSoup(jobs_rep.text, 'html.parser')
        jobs_name = jobs_soup.find_all('div', 'y735df0 _1iz8dgs6q _1iz8dgs6v')
        jobs_company = jobs_soup.find_all('span', 'y735df0 _1iz8dgs4y _94v4w0 _94v4w1 _94v4w21 _1wzghjf4 _94v4wd') 
        jobs_location = jobs_soup.find('span', 'y735df0 _1iz8dgs4y _1iz8dgsr')
        jobs_position = jobs_location.find_next('span', 'y735df0 _1iz8dgs4y _1iz8dgsr')
        jobs_level = jobs_position.find_next('span', 'y735df0 _1iz8dgs4y _1iz8dgsr')
        jobs_salary = jobs_level.find_next('span', 'y735df0 _1iz8dgs4y _1iz8dgsr') 
                                    
        for name in jobs_name:
            name = name.h1
            if name != None:
                match = re.search(r">([^<]*)<", str(name))
                name = match.group(1)
                lst_name.append(name)

        for company in jobs_company:
            if company != None:
                if company.find('a') != None:
                    match = re.search(r">([^<]*)</a", str(company))
                    company = match.group(1)
                else:
                    match = re.search(r">([^<]*)<", str(company))
                    company = match.group(1)
            lst_company.append(company)

        for location in jobs_location:
            if location != None:
                lst_location.append(location)

        for position in jobs_position:
            lst_position.append(position)

        for level in jobs_level:
            lst_level.append(level)
                                        
        big_lst.append(jobs_salary)
    for i in big_lst:
        if i != None:
            match = re.search(r">([^<]*)<", str(i))
            i = match.group(1)
            lst_salary.append(i)
        else:
            lst_salary.append("None")
                                </code>
                            </pre>
                        </div>

                        <h5>Using recursion to go to the next page:</h5>
                        <div class="code-container">
                            <pre>
                                <code>
    #going to the next pages
    next_card = soup.find_all('li', 'y735df0 _1iz8dgsa6 _1iz8dgs9v _1iz8dgsw')
    for n_link in next_card:
        n_link = n_link.find('a').get('href')
        if n_link != None:
            return extract("https://www.seek.com.au"+str(n_link))
        else: 
            break
                                </code>
                            </pre>
                        </div>

                        <h5>Run the function and import all data into a CSV file:</h5>
                        <p>The piece of code from this point is outside the main(extract) function.</p>
                        <div class="code-container">
                            <pre>
                                <code>
extract("https://www.seek.com.au/jobs-in-engineering/in-Northern-QLD")
#import all data into a spread sheet
with open('test.csv', 'w', newline='') as file:
    writer = csv.writer(file)
    
    # Write header row
    writer.writerow(["Name", "Company", "Position", "Location", "Salary", "Level", "Link to jobs"])
    
    # Write data rows
    for data in zip(lst_name, lst_company, lst_position, lst_location, lst_salary, lst_level, lst_links):
        writer.writerow(data)
                                </code>
                            </pre>
                        </div>

                        <h5>Result:</h5>
                        <p>The first data set collect all electrical engineering jobs accross Perth WA:</p>
                        <a href="assets\project_2\data_set_1.csv">Link to the excel file</a>
                        <p>For some reason, the data from each column does not match each other starting from page 2. This bug might be due to how the bot seperatly collect each set of data, causing different length of data list when one job does not contain every pieces of data. This will be fixed on data set 2.</p>
                        <p>Discussion: for some reason, after the first or second page, data from each column does match each other. This bug could be the result of missing information from the hiring pages, causing the difference in length among the data lists</p>
                    </div>

                    <div class="col-12 col-md-3 offset-md-1 meta">
                        <div class="tags"><span class="meta-heading">Tags</span><a href="https://github.com/namhai2307/Automated-jobs-scraping-bot" target="_blank">Resource(Github)</a><a href="#">Project</a><span class="meta-heading">Date</span><span>20-02-2024</span></div>
                    </div>
                </div>
                <div class="more-projects">
                    <h3 class="text-center">More Projects</h3><img class="img-fluid scale-on-hover" src="assets\image material\project vrc.jpg"><img class="img-fluid scale-on-hover" src="assets/img/nature/image3.jpg"><img class="img-fluid scale-on-hover" src="assets/img/tech/image4.jpg"><img class="img-fluid scale-on-hover" src="assets/img/nature/image5.jpg"><img class="img-fluid scale-on-hover" src="assets/img/nature/image4.jpg">
                    <div class="row gallery">
                        <div class="col-md-4 col-lg-3">
                            <div class="item"><a href="#"></a></div>
                        </div>
                        <div class="col-md-4 col-lg-3">
                            <div class="item"><a href="#"></a></div>
                        </div>
                        <div class="col-md-4 col-lg-3">
                            <div class="item"><a href="#"></a></div>
                        </div>
                        <div class="col-md-4 col-lg-3">
                            <div class="item"><a href="#"></a></div>
                        </div>
                    </div>
                </div>
            </div>
        </section>
    </main>
    <footer class="page-footer">
        <div class="container">
            <div class="links"><a href="#">About me</a><a href="https://www.linkedin.com/in/nam-tr%E1%BA%A7n-514905279/">My Linkedin</a><a href="projects-grid-cards.html">Projects</a></div>
            <div class="social-icons"><a href="https://www.linkedin.com/in/nam-tr%E1%BA%A7n-514905279/"><i class="icon ion-social-linkedin"></i></a></div>
        </div>
    </footer>
    <script src="assets/bootstrap/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/pikaday/1.6.1/pikaday.min.js"></script>
    <script src="assets/js/theme.js"></script>
</body>

</html>